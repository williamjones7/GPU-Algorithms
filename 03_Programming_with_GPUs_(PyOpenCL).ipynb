{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyOpenCL\n",
        "\n",
        "You can program on GPUs using two main frameworks: (1) Cuda and (2) OpenCL. In a sense, these frameworks is a set of instructions to communate with the GPU and these frameworks have been implemented in many languages like Java and Python. Note, these are not the only frameworks but are the main ones.\n",
        "\n",
        "Cuda is specifically for Nvidia GPUs, while OpenCL can be used for general GPUs. Due the speciality, Cuda tends to have a slight advantage over OpenCL. In fact, some games have special optimizations for Nvidia GPUs.\n",
        "\n",
        "Cuda and OpenCL have slightly different syntaxes but are fundamentally the same. Note that Cupy is written in Cuda."
      ],
      "metadata": {
        "id": "WKtFN9sfDviZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For some reason we need this to install pyopencl on Colab\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale=True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "n9_SV0-OINL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyopencl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Rzh0j9GzlJ",
        "outputId": "c20fb772-8896-4d25-e1ec-690f4c5267a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyopencl in /usr/local/lib/python3.8/dist-packages (2022.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyopencl) (1.21.6)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pyopencl) (3.0.0)\n",
            "Requirement already satisfied: pytools>=2021.2.7 in /usr/local/lib/python3.8/dist-packages (from pyopencl) (2022.1.14)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.8/dist-packages (from pytools>=2021.2.7->pyopencl) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyopencl as cl"
      ],
      "metadata": {
        "id": "ZqC7XwUpfFzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl.get_platforms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db_EgpvdGyn-",
        "outputId": "550c411b-9feb-49f2-9797-089c19127109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<pyopencl.Platform 'NVIDIA CUDA' at 0x2929ae0>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[platform.get_devices() for platform in cl.get_platforms()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD4DF6xwIXTj",
        "outputId": "cc03940e-730a-46e7-f655-26af67d2cab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<pyopencl.Device 'Tesla T4' on 'NVIDIA CUDA' at 0x2929b30>]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for platform in cl.get_platforms():\n",
        "    for device in platform.get_devices():\n",
        "        print(f\"Name: {device.name}\")\n",
        "        print(f\"Global Memory: {device.global_mem_size / 2**30} GB\")\n",
        "        print(f\"Global Cache: {device.global_mem_cache_size / 2**10} KB\")\n",
        "        print(f\"Local Memory: {device.local_mem_size / 2**10} KB\")\n",
        "        print(f\"Compute Units: {device.max_compute_units}\")\n",
        "        print(f\"Work Group Size: {device.max_work_group_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtEMoE64Ibt1",
        "outputId": "6b7955ae-3480-4064-b8e6-206a5ebd39ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Tesla T4\n",
            "Global Memory: 14.7557373046875 GB\n",
            "Global Cache: 1280.0 KB\n",
            "Local Memory: 48.0 KB\n",
            "Compute Units: 40\n",
            "Work Group Size: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Memory\n",
        "\n",
        "Everything you do in Python, all the variables and datasets in Numpy, is stored in the CPU memory. However, the GPU memory is not shared with the CPU, so data must be sent from the CPU to the GPU. This typically is the major bottleneck of using GPUs, so you want to reduce the amount of data you want to send and receive from the CPU. More than that, the code that you want to run on the GPU must be 'programmed' on the GPU before it can be run.\n",
        "\n",
        "Similarly, if you have multiple GPUs sending things to and from GPUs is also very expensive. So you can have instances where using two GPUs takes longer than using only one."
      ],
      "metadata": {
        "id": "OjQHks717Pt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context and Queues\n",
        "\n",
        "Context and queues are how you build and run things on the GPU.\n",
        "\n",
        "A context is a namespace you want your programs and variables to live. Programs and variables in different contexts cannot see each other and cannot be added together. Using programs with different namespaces as your variables will also raise an error. You can think of the context as the memory shared and not with memory associated with another context.\n",
        "\n",
        "Once the programs have been loaded and built in the context, we use queues to submit our jobs (known as events). Notably, submitting to the queue is performed asynchronously - once you submit your job to the queue, OpenCL will not wait for the job to finish, and the rest of your code will continue to run. This will only be an issue if the future code depends on the values of the previous code. In this case, you can wait for the job to finish before continuing on."
      ],
      "metadata": {
        "id": "qC0hgcog1fSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyopencl.array as cl_array\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "yxZLTXDNQ9V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "platform = cl.get_platforms()\n",
        "devices = platform[0].get_devices()"
      ],
      "metadata": {
        "id": "NCvFozTQvMrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = cl.Context(devices)\n",
        "queue = cl.CommandQueue(context)"
      ],
      "metadata": {
        "id": "m5zFemFlQ6Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queue2 = cl.CommandQueue(context)"
      ],
      "metadata": {
        "id": "hEkAxEKu2nkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(10_000).astype(np.float32)\n",
        "y = np.random.rand(10_000).astype(np.float32)\n",
        "\n",
        "# Send data to the gpu\n",
        "x_gpu = cl_array.to_device(queue, x)\n",
        "y_gpu = cl_array.to_device(queue, y)"
      ],
      "metadata": {
        "id": "vzXr3slc1ZZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform addition on the gpu\n",
        "out = x_gpu + y_gpu"
      ],
      "metadata": {
        "id": "wfBwzur31_f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elementwise Kernel\n",
        "\n",
        "The element-wise kernel is the simplest way to start programming on a GPU but is very restrictive. If you have an operation that applies to each list element without requiring other elements, then the element-wise kernel is the best."
      ],
      "metadata": {
        "id": "9cJFHD11hxX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Affine Operation\n",
        "\n",
        "$$mx + b$$\n",
        "for $m\\in\\mathbb{R}, x\\in\\mathbb{R}^n, b\\in\\mathbb{R}^n$"
      ],
      "metadata": {
        "id": "CNfUThVH9wFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyopencl.elementwise import ElementwiseKernel"
      ],
      "metadata": {
        "id": "pDWUoBsP9wYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The arguments for `ElementwiseKernel` is\n",
        "    \n",
        "1. The context\n",
        "2. The arguments to the function\n",
        "3. The operation you want to apply to each element\n",
        "3. The name of the function to be stored in the context"
      ],
      "metadata": {
        "id": "mvJMHToFAoiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add_program = ElementwiseKernel(context, \n",
        "                                \"double m, double *x, double *b, double *out\",\n",
        "                                \"out[i] = m * x[i] + b[i]\", \n",
        "                                \"add\")"
      ],
      "metadata": {
        "id": "Io_CVJWUD2d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What happens if we change the type to np.float32\n",
        "x = np.random.rand(10_000).astype(np.float64) - 0.5\n",
        "b = np.random.rand(10_000).astype(np.float64)\n",
        "\n",
        "x_gpu = cl_array.to_device(queue, x)\n",
        "b_gpu = cl_array.to_device(queue, b)"
      ],
      "metadata": {
        "id": "tWKW2gIfD3wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = cl_array.zeros_like(x_gpu)\n",
        "add_program(np.float64(0.1), x_gpu, b_gpu, out)"
      ],
      "metadata": {
        "id": "JIus1icyD2Xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63126141-ff66-46ad-9cf0-6ab13f5f1c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyopencl._cl.Event at 0x7f014c1680e0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will notice that this returns an `Event`, meaning that this is happening asynchronously. So if you want to make sure the event is finished you need to do the following"
      ],
      "metadata": {
        "id": "QpGkkLjGA-fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = cl_array.zeros_like(x_gpu)\n",
        "event = add_program(np.float64(0.1), x_gpu, b_gpu, out)\n",
        "event.wait()"
      ],
      "metadata": {
        "id": "HauHVvxQBT9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_almost_equal(out.get(), 0.1 * x + b)"
      ],
      "metadata": {
        "id": "9g4U23-eD7gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReLu"
      ],
      "metadata": {
        "id": "pbPMSjCIEE89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relu_program = ElementwiseKernel(context, \n",
        "                                 \"double *x, double *out\",\n",
        "                                 \"out[i] = x[i] > 0 ? x[i] : 0.0\", \n",
        "                                 \"relu\")"
      ],
      "metadata": {
        "id": "kNoHrK9mD520"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid\n",
        "The sigmoid function is defined as\n",
        "$$f(x) = \\frac{1}{1 + e^{-x}}.$$\n",
        "But this function is famously is numerically unstable. As $x\\to\\infty,\\ f(x)\\to 1$ and as $x\\to-\\infty,\\ f(x)\\to 0$. This function is bounded, but not well behaved when $x \\to -\\infty$."
      ],
      "metadata": {
        "id": "-4cQTh2lEJTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "BfhwkrhVE6iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 1e3\n",
        "f(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxsxbr3NGMwq",
        "outputId": "c363c4d6-95bb-42b1-83c3-bd8b00c01a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = -1e3\n",
        "f(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7mJbCwTE9W6",
        "outputId": "febc48fe-da85-4ebe-fe61-27f2baf21fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-a3ebedcd0b6b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is because of overflows, vs underflows"
      ],
      "metadata": {
        "id": "EH2VmsUvGU_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stable_f(x):\n",
        "    if x > 0:\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    else:\n",
        "        temp = np.exp(x)\n",
        "        return  temp / (1 + temp)"
      ],
      "metadata": {
        "id": "hLhpv5-3Fm2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 1e3\n",
        "stable_f(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugyb8YhhFxrv",
        "outputId": "b0e1f384-66f0-4cce-800c-d9238774fe7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = -1e3\n",
        "stable_f(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeUes72_F8X3",
        "outputId": "2391a29e-09e8-4f08-fde3-3f1aea5fcafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(-100000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_QaUFKEFRuT",
        "outputId": "e7740935-43e1-4157-f44d-7c4851f6e514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-a3ebedcd0b6b>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stable_sigmoid(x):\n",
        "    out = np.zeros_like(x)\n",
        "    mask = x > 0\n",
        "\n",
        "    out[mask] = 1 / (1 + np.exp(-x[mask]))\n",
        "\n",
        "    temp = np.exp(x[~mask])\n",
        "    out[~mask] = temp / (1 + temp)\n",
        "    \n",
        "    return out"
      ],
      "metadata": {
        "id": "OGwqNF1TGyAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid_program = ElementwiseKernel(context,\n",
        "                                    \"double *x, double *out\",\n",
        "                                    \"out[i] = SIGMOID(x[i])\",\n",
        "                                    \"sigmoid\",\n",
        "                                    preamble='#define SIGMOID(x) x > 0 ? 1.0/(1.0 + exp(-x)) : exp(x) / (exp(x) + 1.0)'\n",
        "                                    )"
      ],
      "metadata": {
        "id": "McZH2nyE-kMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = (np.random.rand(10_000).astype(np.float64) - 0.5) * 1e4\n",
        "\n",
        "x_gpu = cl_array.to_device(queue, x)"
      ],
      "metadata": {
        "id": "jcIkfuHpA-bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = cl_array.zeros_like(x_gpu)\n",
        "sigmoid_program(x_gpu, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPeZvwMs-kKW",
        "outputId": "8c55ce41-4d1e-41ba-fdd5-bd98b43b1e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyopencl._cl.Event at 0x7f014c0d3810>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_almost_equal(stable_sigmoid(x), out.get())"
      ],
      "metadata": {
        "id": "JfwpIx3WB-1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Program\n",
        "\n",
        "If our operation requires more involved access to other indices, we need to write our own kernel.\n",
        "\n",
        "Before we get into that, a GPU is made up of thousands of workers, more specifically threads, who work in parallel. These workers have no structure to them, but we can 'organize' them up to 3-dimensions. These dimensions only help us organize the workers into easy layouts that may help certain programs.\n",
        "\n",
        "These dimensions is accessed through `get_global_id`."
      ],
      "metadata": {
        "id": "uxVEvHJg3veZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add_c_code = \"\"\"\n",
        "__kernel void add(float m, __global float *a, __global float *b, __global float *out){\n",
        "    int index = get_global_id(0);\n",
        "    out[index] = m * a[index] + b[index];\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LFndD16y3vCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program = cl.Program(context, add_c_code).build()"
      ],
      "metadata": {
        "id": "W0Vb4mr84un6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.rand(1000).astype(np.float32)\n",
        "b = np.random.rand(1000).astype(np.float32)\n",
        "\n",
        "a_gpu = cl_array.to_device(queue, a)\n",
        "b_gpu = cl_array.to_device(queue, b)"
      ],
      "metadata": {
        "id": "egBahtwFHsBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_size = a_gpu.shape\n",
        "local_size = None\n",
        "\n",
        "out_gpu = cl_array.zeros_like(a_gpu)\n",
        "program.add(queue, global_size, local_size, \n",
        "            np.float32(0.1), a_gpu.data, b_gpu.data, out_gpu.data)"
      ],
      "metadata": {
        "id": "YNsxFSqS44QF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1578e4f-048c-4546-8340-21a4a35145f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyopencl._cl.Event at 0x7f014c15c810>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_almost_equal(out_gpu.get(), 0.1 * a + b)"
      ],
      "metadata": {
        "id": "tFEPibPcHd2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if we change x into a matrix, rather than a vector"
      ],
      "metadata": {
        "id": "qD0j-i3qGHdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(500, 500).astype(np.float32)\n",
        "y = np.random.rand(500, 500).astype(np.float32)\n",
        "\n",
        "x_gpu2 = cl_array.to_device(queue, x)\n",
        "y_gpu2 = cl_array.to_device(queue, y)"
      ],
      "metadata": {
        "id": "PIOdMgPRI1xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_size = x_gpu2.shape\n",
        "local_size = None\n",
        "\n",
        "out_gpu = cl_array.zeros_like(x_gpu2)\n",
        "program.add(queue, global_size, local_size, \n",
        "            np.float32(1), x_gpu2.data, y_gpu2.data, out_gpu.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrjO67FbI6-G",
        "outputId": "1c6d0287-a7d4-479d-ee68-dd8a4bc45af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyopencl._cl.Event at 0x7f014c0e1d10>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_almost_equal(out_gpu.get(), x + y)"
      ],
      "metadata": {
        "id": "ZQ28L935I-6U",
        "outputId": "8d568ecd-95a4-4364-b491-53e9f0d9e5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-aa0be8bf931a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_almost_equal\u001b[0;34m(actual, desired, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0massert_array_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;31m# If one of desired/actual is not finite, handle it specially here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_almost_equal\u001b[0;34m(x, y, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m     assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n\u001b[0m\u001b[1;32m   1047\u001b[0m              \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Arrays are not almost equal to %d decimals'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m              precision=decimal)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    842\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 7 decimals\n\nMismatched elements: 249500 / 250000 (99.8%)\nMax absolute difference: 1.9987956\nMax relative difference: 1.\n x: array([[0.7357498, 1.1241858, 1.2360364, ..., 0.8294325, 0.617823 ,\n        0.6515197],\n       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,...\n y: array([[0.7357498, 1.1241858, 1.2360364, ..., 0.8294325, 0.617823 ,\n        0.6515197],\n       [1.2713516, 0.7060885, 0.9396349, ..., 1.8167584, 0.5139595,..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That didn't work. But why?\n",
        "\n",
        "To fix it we need to change the `global_size`. The `global_size` defines how we distribute the workers. Before, we had the `global_size = (500, 500)`, so we split our workers into 2-dimensions with 500 in the 1st and 500 in the 2nd dimension. But our code only used `get_global_id(0)`, so eventhough all workers are in use, only it's first dimension is in use and the 2nd dimension becomes redundant.\n",
        "\n",
        "We can fix this in two ways. \n",
        "1. First, we can use `get_global_id(1)` to use the 2nd dimension, or \n",
        "2. We can change `global_size = (500 * 500,)` and only use `get_global_id(0)`. Effectively this transforms the kernel into an element-wise kernel"
      ],
      "metadata": {
        "id": "vzOE9ECVGPiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(500, 500).astype(np.float32)\n",
        "y = np.random.rand(500, 500).astype(np.float32)\n",
        "\n",
        "x_gpu2 = cl_array.to_device(queue2, x)\n",
        "y_gpu2 = cl_array.to_device(queue2, y)"
      ],
      "metadata": {
        "id": "0-TBGV6A6UG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_size = (int(np.prod(x_gpu2.shape)),)\n",
        "local_size = None\n",
        "\n",
        "out_gpu = cl_array.zeros_like(x_gpu2)\n",
        "program.add(queue, global_size, local_size, \n",
        "            np.float32(1), x_gpu2.data, y_gpu2.data, out_gpu.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyUnQaqz3u_I",
        "outputId": "3c76efc6-a121-4cf7-ec18-d1158aad81e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyopencl._cl.Event at 0x7f014c00c450>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_almost_equal(out_gpu.get(), x + y)"
      ],
      "metadata": {
        "id": "-uxVbmuM7ig3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_c_code = \"\"\"\n",
        "__kernel void add(float m, __global float *a, __global float *b, __global float *out){\n",
        "    int index = get_global_id(0);\n",
        "    out[index] = m * a[index] + b[index];\n",
        "}\n",
        "\n",
        "__kernel void add_2d(float m, __global float *a, __global float *b, int width, __global float *out){\n",
        "    int col = get_global_id(0);\n",
        "    int row = get_global_id(1);\n",
        "\n",
        "    int index = row * width + col;\n",
        "    out[index] = m * a[index] + b[index];\n",
        "}\n",
        "\n",
        "__kernel void add_2d_v2(float m, __global float *a, __global float *b, int height, __global float *out){\n",
        "    int row = get_global_id(0);\n",
        "    int col = get_global_id(1);\n",
        "\n",
        "    int index = row + col * height;\n",
        "    out[index] = m * a[index] + b[index];\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EbJHja_47icl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program = cl.Program(context, add_c_code).build()"
      ],
      "metadata": {
        "id": "7fj9kkkxCndh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(5000, 500).astype(np.float32)\n",
        "y = np.random.rand(5000, 500).astype(np.float32)\n",
        "\n",
        "x_gpu2 = cl_array.to_device(queue, x)\n",
        "y_gpu2 = cl_array.to_device(queue, y)"
      ],
      "metadata": {
        "id": "C2rgVALcCnbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_size = None\n",
        "\n",
        "height, width = x.shape\n",
        "\n",
        "out_gpu = cl_array.zeros_like(x_gpu2)\n",
        "event = program.add_2d(queue, x.shape[::-1], local_size, \n",
        "                       np.float32(1), x_gpu2.data, y_gpu2.data, np.int32(width), out_gpu.data)\n",
        "event.wait()\n",
        "np.testing.assert_almost_equal(out_gpu.get(), x + y)\n",
        "\n",
        "\n",
        "out_gpu = cl_array.zeros_like(x_gpu2)\n",
        "event = program.add_2d_v2(queue, x.shape, local_size, \n",
        "                          np.float32(1), x_gpu2.data, y_gpu2.data, np.int32(height), out_gpu.data)\n",
        "event.wait()\n",
        "np.testing.assert_almost_equal(out_gpu.get(), x + y)"
      ],
      "metadata": {
        "id": "DHIZy2twCt8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_almost_equal(out_gpu.get(), x + y)"
      ],
      "metadata": {
        "id": "j1a25uqbDNMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -r 7 -n 100\n",
        "event = program.add_2d(queue, x.shape[::-1], local_size, \n",
        "                       np.float32(1), x_gpu2.data, y_gpu2.data, np.int32(width), out_gpu.data)\n",
        "event.wait()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR_q0RWlWX_i",
        "outputId": "5afbb765-debf-4f12-bf28-0fc79969026f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251 µs ± 21 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -r 7 -n 100\n",
        "event = program.add_2d_v2(queue, x.shape, local_size, \n",
        "                          np.float32(1), x_gpu2.data, y_gpu2.data, np.int32(height), out_gpu.data)\n",
        "event.wait()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A82CMWbFWjPE",
        "outputId": "b04b48bb-3285-4fc8-f535-cb4c16e70992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277 µs ± 36.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transpose\n",
        "\n",
        "As you may recall, the transpose of a matrix performs the operation $A_{i,j}\\to A_{j,i}$. This can be implemented trivally using the 2D organization of the workers, as seen in `naive_transpose`.\n",
        "\n",
        "You may have noticed the `__global` in the code, as well as the `global_size` and `local_size`. Like a CPU, GPUs have a global memory that is shared among all the workers but also a local memory that is shared with the local workers. As fast as global memory is, local memory is always going to be faster. \n",
        "\n",
        "### Aside - Row Major or Column Major\n",
        "Let's say that we have a matrix\n",
        "$$A = \\begin{pmatrix}1 & 2 & 3\\\\ 4 & 5 & 6\\\\ 7 & 8 & 9\\end{pmatrix}.$$\n",
        "\n",
        "Numpy stores vectors and matrices as a contiguous memory block. Meaning that when you create a new matrix, Numpy will cut out a continuous chunk of memory and store all the numbers in that chunk of memory. It can store all the numbers by the row major (C-contiguous)\n",
        "$$(1, 2, 3, 4, 5, 6, 7, 8, 9)$$\n",
        "or by column major (Fortran-contiguous)\n",
        "$$(1, 4, 7, 2, 5, 8, 3, 6, 9)$$"
      ],
      "metadata": {
        "id": "kpMJoVabQ4Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.random.rand(3, 3)\n",
        "x.flags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSTKZ8LrtYF6",
        "outputId": "5a69ee23-1ee8-4f19-b742-e0409dd08ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  C_CONTIGUOUS : True\n",
              "  F_CONTIGUOUS : False\n",
              "  OWNDATA : True\n",
              "  WRITEABLE : True\n",
              "  ALIGNED : True\n",
              "  WRITEBACKIFCOPY : False\n",
              "  UPDATEIFCOPY : False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.T.flags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2qr6Crptdq4",
        "outputId": "dfc25ed7-c3f3-43da-82c4-4c0b3e1458db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  C_CONTIGUOUS : False\n",
              "  F_CONTIGUOUS : True\n",
              "  OWNDATA : False\n",
              "  WRITEABLE : True\n",
              "  ALIGNED : True\n",
              "  WRITEBACKIFCOPY : False\n",
              "  UPDATEIFCOPY : False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is the transpose of a matrix Fortran-Contiguous not C-contiguous?"
      ],
      "metadata": {
        "id": "yGQ1wuZYthQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Aside to the Aside - Non-contiguous Memory\n",
        "It may or may not be hard to know what a non-contiguous memory block means. Non-contiguous memory follows a linked-list structure. \n",
        "\n",
        "https://levelup.gitconnected.com/array-vs-linked-list-data-structure-c5c0ff405f16\n"
      ],
      "metadata": {
        "id": "sJHpszD4tXE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coalescing Memory\n",
        "By default, OpenCl stores matrices a C-contiguous memory. So for a $[n\\times m]$ matrix, the memory looks something like\n",
        "$$(A_{0, 0}, A_{0, 1}, \\cdots, A_{i,j}, A_{i, j + 1}, A_{i, j + 2}, A_{i, j + 3}, \\cdots, A_{n, m-1}, A_{n, m})$$\n",
        "\n",
        "Now the transpose requires access"
      ],
      "metadata": {
        "id": "lK9QstPct88I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Coalescing Memory\n",
        "\n",
        "\n",
        "https://www.cs.rochester.edu/~cding/Archive/MSP04Proceedings/p2_kawahito.pdf\n"
      ],
      "metadata": {
        "id": "tZUGiYBZkN7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/inducer/pyopencl/blob/main/examples/transpose.py\n",
        "# https://github.com/sschaetz/nvidia-opencl-examples/blob/master/OpenCL/src/oclTranspose/transpose.cl"
      ],
      "metadata": {
        "id": "wkViFQ-0YR_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transpose_program = \"\"\"\n",
        "#define BLOCK_SIZE 16\n",
        "#define A_BLOCK_STRIDE (BLOCK_SIZE * width)\n",
        "#define A_T_BLOCK_STRIDE (BLOCK_SIZE * height)\n",
        "\n",
        "__kernel void naive_transpose(__global float *a_t, __global float *a, int width, int height){\n",
        "    unsigned int col = get_global_id(1);\n",
        "    unsigned int row = get_global_id(0);\n",
        "\n",
        "    a_t[col * height + row] = a[row * width + col];\n",
        "}\n",
        "\n",
        "__kernel void transpose(__global float *a_t, __global float *a, int width, int height, __local float *a_local){\n",
        "    int global_col = get_global_id(0);\n",
        "    int global_row = get_global_id(1);\n",
        "\n",
        "    int local_col = get_local_id(0);\n",
        "    int local_row = get_local_id(1);\n",
        "\n",
        "    int local_index = local_row * BLOCK_SIZE + local_col;\n",
        "\n",
        "    a_local[local_index] = a[global_row * width + global_col];\n",
        "\n",
        "    barrier(CLK_LOCAL_MEM_FENCE);\n",
        "\n",
        "    int group_col = get_group_id(0);\n",
        "    int group_row = get_group_id(1);\n",
        "\n",
        "    /* Transpose the blocks */\n",
        "    global_row = group_col * BLOCK_SIZE + local_row;\n",
        "    global_col = group_row * BLOCK_SIZE + local_col;\n",
        "\n",
        "    a_t[global_row * height + global_col] = a_local[local_col * BLOCK_SIZE + local_row];\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5xeggzVdRBXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "program = cl.Program(context, transpose_program).build()"
      ],
      "metadata": {
        "id": "D6L3KmGnRHE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 16"
      ],
      "metadata": {
        "id": "pA7u30-HNJkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(2 ** 13, 2 ** 13).astype(np.float32)\n",
        "x_device = cl_array.to_device(queue, x)\n",
        "\n",
        "x.shape"
      ],
      "metadata": {
        "id": "nX0ROz8pIuZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa60b7f-3d37-4611-e345-31506fa2e981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8192, 8192)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_size = x_device.shape\n",
        "local_size = (BLOCK_SIZE, BLOCK_SIZE)\n",
        "\n",
        "width, height = x_device.shape\n",
        "\n",
        "x_local = cl.LocalMemory(4 * BLOCK_SIZE * (BLOCK_SIZE + 1))\n",
        "x_transpose = cl_array.zeros_like(x_device)"
      ],
      "metadata": {
        "id": "WWQvfegzfyhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event = program.transpose_v3(queue, global_size, local_size,\n",
        "                               x_transpose.data, x_device.data, np.int32(width), np.int32(height), x_local)\n",
        "event.wait()"
      ],
      "metadata": {
        "id": "kpSqFXPIUGce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_almost_equal(x_transpose.get(), x.T)"
      ],
      "metadata": {
        "id": "q-C4dNzwgVk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "event = program.naive_transpose(queue, global_size, local_size,\n",
        "                                x_transpose.data, x_device.data, np.int32(width), np.int32(height))\n",
        "event.wait()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK8HfyWvhWbY",
        "outputId": "f57b7ce1-a75b-4015-b022-4529ed48e8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.03 ms ± 57.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "event = program.transpose(queue, global_size, local_size,\n",
        "                          x_transpose.data, x_device.data, np.int32(width), np.int32(height), x_local)\n",
        "event.wait()"
      ],
      "metadata": {
        "id": "KPMRNtLJfXGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2941da31-14fd-4160-e75c-5272c2f73a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.55 ms ± 6.66 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning It Up\n",
        "It is a lot of code to write if we want to take the transpose of a matrix. To make it simpler, we will use classes"
      ],
      "metadata": {
        "id": "3OVyRxBrwZxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPUTranspose:\n",
        "    def __init__(self, context, queue):\n",
        "        self.context = context\n",
        "        self.queue = queue\n",
        "        self.program = cl.Program(self.context, transpose_program).build()\n",
        "\n",
        "    def transpose(self, x):\n",
        "        \"\"\"  x is assumed to be on the device \"\"\"\n",
        "        global_size = x.shape\n",
        "        local_size = (16, 16)\n",
        "\n",
        "        width, height = x.shape\n",
        "\n",
        "        x_transpose = cl_array.zeros_like(x)\n",
        "        a_local = cl.LocalMemory(4 * 16 * (16 + 1))\n",
        "        \n",
        "        self.program.transpose(self.queue, global_size, local_size,\n",
        "                               x_transpose.data, x.data, np.int32(width), np.int32(height), a_local).wait()\n",
        "        return x_transpose\n",
        "\n",
        "    def naive_transpose(self, x):\n",
        "        global_size = x.shape\n",
        "        local_size = None\n",
        "\n",
        "        x_transpose = cl_array.zeros_like(x)\n",
        "        self.program.naive_transpose(queue, global_size, local_size,\n",
        "                                     x_transpose.data, x.data, np.int32(width), np.int32(height)).wait()\n",
        "        return x_transpose"
      ],
      "metadata": {
        "id": "Vmxqq2iRirUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_transpose = GPUTranspose(context, queue)"
      ],
      "metadata": {
        "id": "2i2rnf9gyFxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(16 * 1000, 16 * 1000).astype(np.float32)\n",
        "x_device = cl_array.to_device(queue, x)"
      ],
      "metadata": {
        "id": "8MwqRephyPN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "x_transpose = gpu_transpose.transpose(x_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvycnc2fyWie",
        "outputId": "04c441b3-a41d-4b47-b691-01c607506692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.2 ms ± 140 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "x_transpose = gpu_transpose.naive_transpose(x_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1lYx6p7ynIo",
        "outputId": "c965ed2e-c42a-47ae-b2bb-7dbb20314b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.5 ms ± 660 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question\n",
        "1. Try and write the 2D heat equation solver using PyOpenCL\n",
        "2. Try and write the sum of an array"
      ],
      "metadata": {
        "id": "P0GsGep9WdxJ"
      }
    }
  ]
}